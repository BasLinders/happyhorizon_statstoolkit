import streamlit as st
from scipy.stats import norm
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from prophet import Prophet

st.set_page_config(
    page_title="Pre-test analysis",
    page_icon="ðŸ”¢",
)

# --- USER INPUT ---

# User input for both MDE and sample size calculation
def get_user_input():
    st.write("### Baseline Data")
    st.write("Enter weekly visitors, weekly conversions and test parameters.")

    col1, col2 = st.columns(2)
    # Baseline data
    with col1:
        st.number_input("Number of variants (including control):", min_value=2, step=1, value=st.session_state.get("num_variants", 2), key="num_variants")
        st.number_input("Visitors in baseline variant:", min_value=0, step=1, value=st.session_state.get("baseline_visitors", 0), key="baseline_visitors")
        st.number_input("Conversions in baseline variant:", min_value=0, step=1, value=st.session_state.get("baseline_conversions", 0), key="baseline_conversions")

    # Test parameter input
    with col2:
        st.number_input("Desired confidence level (e.g., 90%):", min_value=0, max_value=100, step=1, value=st.session_state.get("risk", 95), key="risk")
        st.number_input("Minimum trustworthiness (Power) (e.g., 80%):", min_value=0, max_value=100, step=1, value=st.session_state.get("trust", 80), key="trust")
        if st.session_state.get("calculation_mode") == "Calculate Sample Size based on MDE":
            st.number_input("What MDE are you aiming for?", min_value=1, max_value=100, step=1, value=st.session_state.get("mde", 5), key="mde")
    st.radio(
        "Hypothesis type ('One-sided' or 'Two-sided'): ",
        options=['One-sided', 'Two-sided'], 
        index=['One-sided', 'Two-sided'].index(st.session_state.get("tails", 'One-sided')),
        horizontal=True,
        key="tails",
        help="Choose 'One-sided' when testing only for improvement (B > A) or decline (B < A); this requires fewer samples and results in a possible lower MDE. Choose 'Two-sided' when testing for any difference (better or worse); this is more comprehensive because it can detect significant effects in either direction, but generally requires more samples and possibly raises the MDE."
    )

# --- HELPER FUNCTIONS ---

# Holm-Bonferroni correction for MDE calculation
def holm_bonferroni(num_variants, alpha, tails):
    adjusted_alpha = alpha / np.arange(num_variants, 0, -1)
    if tails == 'Two-sided':
        z_alpha = norm.ppf(1 - adjusted_alpha / 2)
    else:
        z_alpha = norm.ppf(1 - adjusted_alpha)
    return np.max(z_alpha)

def perform_mde_calculation(num_variants, baseline_visitors, baseline_conversions, risk, trust, tails):

    alpha = 1 - (risk / 100)
    power = trust / 100

    # Calculate baseline conversion rate
    baseline_rate = baseline_conversions / baseline_visitors

    # Adjust alpha for multiple comparisons
    if num_variants > 2:
        adjusted_z_alpha = holm_bonferroni(num_variants - 1, alpha, tails)
    else:
        adjusted_z_alpha = norm.ppf(1 - alpha) if tails == 'One-sided' else norm.ppf(1 - alpha / 2)

    # Z-score for power
    z_power = norm.ppf(power)

    # Weekly increments
    weeks = range(1, 7)  # For 6 weeks
    weekly_visitors = int(np.ceil(baseline_visitors / num_variants))

    # Prepare list to store results
    results = []
    for week in weeks:
        visitors_per_variant_weekly = weekly_visitors * week

        # Standard error and MDE calculations
        se = np.sqrt(2 * baseline_rate * (1 - baseline_rate) / visitors_per_variant_weekly)
        mde_absolute = (adjusted_z_alpha + z_power) * se
        mde_relative = (mde_absolute / baseline_rate) * 100

        # Store results
        results.append([week, visitors_per_variant_weekly, mde_relative])

    return results

def display_mde_table(num_variants, baseline_visitors, baseline_conversions, risk, trust, tails):
    results = perform_mde_calculation(num_variants, baseline_visitors, baseline_conversions, risk, trust, tails)
    
    # Display results in a DataFrame
    df = pd.DataFrame(results, columns=['Week', 'Visitors / Variant', 'Relative MDE (%)'])
    df['Relative MDE (%)'] = df['Relative MDE (%)'].map(lambda x: f"{x:.2f}%" if pd.notnull(x) else "N/A")

    # Display the DataFrame
    st.write("## MDE Calculation Results")
    st.write("""
        This table displays the minimum effect size detectable each week. An MDE of <5% is usually testworthy; 5-10% is debatable.
        For larger MDEs, consider whether the effect size can be achieved.
    """)
    if num_variants > 2:
        st.write("")
        st.write(f"*Note: The {holm_bonferroni.__name__ if 'holm_bonferroni' in globals() else 'configured multiple comparison correction'} correction was applied ({num_variants - 1} comparisons) affecting the required significance level.*")
    st.write(df.to_html(index=False), unsafe_allow_html=True)

def calculate_sample_size(num_variants, baseline_visitors, baseline_conversions, mde, risk, trust, tails):

    # --- Input Validation and Parameter Conversion ---

    # Basic validation (although more comprehensive validation should ideally happen in `run`)
    if baseline_visitors <= 0:
        st.error("Baseline visitors must be greater than 0.")
        return # Stop calculation
    if baseline_conversions < 0: # Allow 0 conversions, but not negative
        st.error("Baseline conversions cannot be negative.")
        return
    if baseline_conversions > baseline_visitors:
        st.error("Baseline conversions cannot be greater than baseline visitors.")
        return
    if mde <= 0:
        st.error("Minimum Detectable Effect (MDE) must be greater than 0%.")
        return # Stop calculation

    try:
        mde_relative = mde / 100
        alpha = 1 - (risk / 100)  # Significance level
        power = trust / 100       # Statistical power
        beta = 1 - power          # Type II error rate

        # Baseline conversion rate
        p = baseline_conversions / baseline_visitors

        # Minimum Detectable Effect (absolute)
        mde_absolute = p * mde_relative
        effect_size = mde_absolute

        # Expected conversion rates
        p1 = p
        p2 = p + mde_absolute  # Treatment group rate

        if p2 > 1.0:
            st.warning(f"The calculated treatment conversion rate ({p2:.2%}) exceeds 100% based on the baseline rate ({p:.2%}) and MDE ({mde}%). Please check your inputs.")
        if p2 < 0.0:
             st.warning(f"The calculated treatment conversion rate ({p2:.2%}) is negative based on the baseline rate ({p:.2%}) and MDE ({mde}%). Please check your inputs.")

    except ZeroDivisionError:
        st.error("Error during parameter calculation (potentially division by zero). Please ensure baseline visitors > 0.")
        return
    except Exception as e:
        st.error(f"An unexpected error occurred during parameter setup: {e}")
        return

    st.write("## Sample Size Calculation Results")
    st.write(f"Calculating required sample size for a desired relative MDE of **{mde}%**.")

    # --- Z-Score Calculation ---
    try:
        # Adjust alpha for multiple comparisons if necessary
        if num_variants > 2:
            num_comparisons = num_variants - 1
            z_alpha_adjusted = holm_bonferroni(num_comparisons, alpha, tails)
            correction_applied = True
        else: # num_variants == 2
            if tails == 'One-sided':
                z_alpha_adjusted = norm.ppf(1 - alpha)
            else: # Two-sided
                z_alpha_adjusted = norm.ppf(1 - alpha / 2)
            correction_applied = False

        # Z-score for power (positive value corresponding to 1-beta or power)
        z_power = norm.ppf(1 - beta) # Equivalent to norm.ppf(power)

        if z_alpha_adjusted is None or z_power is None:
             raise ValueError("Z-score calculation failed.")

    except AttributeError:
         st.error("Error: norm.ppf function not found. Ensure scipy is correctly installed.")
         return
    except Exception as e:
        st.error(f"An error occurred during Z-score calculation: {e}")
        return

    # --- Sample Size Formula ---
    try:
        # Variance terms
        var1 = p1 * (1 - p1)
        var2 = p2 * (1 - p2)

        # Ensure variances are non-negative (can happen with p=0 or p=1)
        var1 = max(var1, 0)
        var2 = max(var2, 0)

        # Use approximation p*(1-p) for the first term's variance
        # Or use pooled variance: p_pooled = (p1+p2)/2; var_pooled = p_pooled*(1-p_pooled)
        term1 = z_alpha_adjusted * np.sqrt(2 * p * (1 - p))
        term2 = z_power * np.sqrt(var1 + var2)

        # Required sample size per group
        if effect_size == 0: # Should be caught by MDE > 0 validation earlier
             st.error("Effect size is zero. Cannot calculate sample size.")
             return

        sample_size_per_group = ((term1 + term2) ** 2) / (effect_size ** 2)
        sample_size_per_group = np.ceil(sample_size_per_group)

        if not np.isfinite(sample_size_per_group) or sample_size_per_group <= 0:
            st.error("Calculated sample size is invalid or non-positive. Please check inputs (especially MDE and baseline rates).")
            return

    except ZeroDivisionError:
        st.error("Error calculating sample size (division by zero). This might happen if the MDE is zero.")
        return
    except Exception as e:
        st.error(f"An unexpected error occurred during sample size calculation: {e}")
        return

    # --- Runtime Estimation ---
    def estimate_runtime(ss_per_group, visitors_per_week, n_variants):
        try:
            if visitors_per_week <= 0 or n_variants <= 0:
                return "infinite (zero baseline visitors or variants)"

            daily_visitors_total = visitors_per_week / 7
            visitors_per_group_per_day = daily_visitors_total / n_variants

            if visitors_per_group_per_day <= 0:
                return "infinite (zero daily visitors per group)"

            days_required = ss_per_group / visitors_per_group_per_day
            estimated_days = int(np.ceil(days_required))
            return estimated_days
        except Exception as e:
            st.warning(f"Could not estimate runtime: {e}")
            return "unavailable"

    estimated_days = estimate_runtime(sample_size_per_group, baseline_visitors, num_variants)

    # --- Display Results ---
    st.write(f"The required sample size per group (including control) is **{int(sample_size_per_group):,}**.")
    st.write(f"With an average of **{int(baseline_visitors):,}** total visitors per week, your test is estimated to run for approximately **{estimated_days}** days to reach the required sample size per group.")

    if correction_applied:
        st.write(f"*Note: The {holm_bonferroni.__name__ if 'holm_bonferroni' in globals() else 'configured multiple comparison correction'} correction was applied ({num_comparisons} comparisons) affecting the required significance level.*")

# Forecasting with Prophet
@st.cache_data(show_spinner=False)
def run_prophet_forecast(df, periods=42, confidence_level=0.95):
    """
    Ingests a dataframe with columns ['ds', 'visitors', 'conversions']. Returns a dataframe of forecasted daily values for the next 'periods'days.
    """
    
    # Forecast Visitors
    df_vis = df[['ds', 'visitors']].rename(columns={'visitors': 'y'})
    m_vis = Prophet(yearly_seasonality=True, weekly_seasonality=True, interval_width=confidence_level)
    m_vis.fit(df_vis)
    future_vis = m_vis.make_future_dataframe(periods=periods)
    forecast_vis = m_vis.predict(future_vis)

    # Forecast Conversions
    df_conv = df[['ds', 'conversions']].rename(columns={'conversions': 'y'})
    m_conv = Prophet(yearly_seasonality=True, weekly_seasonality=True, interval_width=confidence_level)
    m_conv.fit(df_conv)
    future_conv = m_conv.make_future_dataframe(periods=periods)
    forecast_conv = m_conv.predict(future_conv)

    # Filter for future data only
    last_date = df['ds'].max()
    
    # Keep yhat_lower and yhat_upper
    cols_to_keep = ['ds', 'yhat', 'yhat_lower', 'yhat_upper']
    
    future_vis = forecast_vis[forecast_vis['ds'] > last_date][cols_to_keep].rename(
        columns={'yhat': 'pred_visitors', 'yhat_lower': 'vis_lower', 'yhat_upper': 'vis_upper'}
    )
    
    future_conv = forecast_conv[forecast_conv['ds'] > last_date][cols_to_keep].rename(
        columns={'yhat': 'pred_conversions', 'yhat_lower': 'conv_lower', 'yhat_upper': 'conv_upper'}
    )
    
    # Merge
    forecast_final = pd.merge(future_vis, future_conv, on='ds')
    
    # Clip negative predictions to 0
    cols_to_clip = ['pred_visitors', 'vis_lower', 'vis_upper', 'pred_conversions', 'conv_lower', 'conv_upper']
    for col in cols_to_clip:
        forecast_final[col] = forecast_final[col].clip(lower=0)
    
    return forecast_final

def perform_mde_calculation_forecast(forecast_df, num_variants, risk, trust, tails):
    """
    Calculates MDE based on accumulating forecasted data rather than static averages.
    """
    alpha = 1 - (risk / 100)
    power = trust / 100

    # Adjust alpha for multiple comparisons
    if num_variants > 2:
        adjusted_z_alpha = holm_bonferroni(num_variants - 1, alpha, tails)
    else:
        adjusted_z_alpha = norm.ppf(1 - alpha) if tails == 'One-sided' else norm.ppf(1 - alpha / 2)

    z_power = norm.ppf(power)

    results = []
    
    # Iterate through weeks 1 to 6
    for week in range(1, 7):
        days_needed = week * 7
        
        # Slice the forecast for this duration
        current_slice = forecast_df.head(days_needed)
        
        # Sum the traffic and conversions to get the "seasonal baseline" for this specific window
        total_visitors = current_slice['pred_visitors'].sum()
        total_conversions = current_slice['pred_conversions'].sum()
        
        if total_visitors <= 0:
            results.append([week, 0, np.nan])
            continue
            
        # Weighted Baseline Conversion Rate for this specific period
        baseline_rate = total_conversions / total_visitors
        baseline_rate = max(0.0001, min(0.9999, baseline_rate)) # ensure rate is valid
        
        # Visitors per variant
        visitors_per_variant = total_visitors / num_variants
        
        # Standard Error & MDE
        se = np.sqrt(2 * baseline_rate * (1 - baseline_rate) / visitors_per_variant)
        mde_absolute = (adjusted_z_alpha + z_power) * se
        mde_relative = (mde_absolute / baseline_rate) * 100
        
        results.append([week, int(visitors_per_variant), mde_relative])
        
    return results

def run():
    st.title("Pre-test analysis")
    """
    This calculator helps you plan for the runtime of your experiment.

    Enter the values below to start.
    """
    with st.expander("How to plan your tests", expanded=False):
        st.markdown("""
        ### How to choose the right method:

        **1. MDE Projection (Fixed Duration)**
        * **Best for:** Strict deadlines.
        * *Scenario:* "We only have 4 weeks to run this test. What is the smallest impact we can reliably detect?"
        * *Output:* A table showing the Minimum Detectable Effect (MDE) achievable for Weeks 1 through 6.

        **2. Sample Size Calculation (Target Effect)**
        * **Best for:** Specific improvement goals.
        * *Scenario:* "We need to detect a 5% lift to justify this feature. How long will that take?"
        * *Output:* The total sample size required and the estimated runtime in days (based on average traffic).

        **3. Seasonal Forecasting (Prophet)**
        * **Best for:** Volatile, high-traffic, or event-driven sites.
        * *Scenario:* "Our traffic spikes on weekends or is approaching a holiday (e.g., Black Friday)."
        * *Why:* Standard calculators assume flat traffic. This method uses your historical data to **forecast** future daily traffic, preventing you from under-powering your test during traffic dips.
        """)

    # Selectbox for choosing the calculation mode
    calculation_mode = st.selectbox(
        "Select Calculation Mode:",
        ("Calculate MDE based on Runtime", "Calculate Sample Size based on MDE", "Seasonal (Prophet Forecast)"),
        help="For stable traffic / conversions, choose either MDE or sample size calculation. If traffic and conversion is seasonal (or highly volatile), choose Seasonal.",
        key="calculation_mode"
    )

    if calculation_mode == "Calculate MDE based on Runtime":
        get_user_input()
        if st.button("Calculate MDE", type="primary"):
            # Validate input using st.session_state
            if (st.session_state.get("baseline_visitors", 0) <= 0 or
                st.session_state.get("baseline_conversions", 0) < 0 or
                st.session_state.get("baseline_conversions", 0) > st.session_state.get("baseline_visitors", 0) or
                not (0 < st.session_state.get("risk", 0) <= 100) or
                not (0 < st.session_state.get("trust", 0) <= 100) or
                st.session_state.get("tails") not in ['One-sided', 'Two-sided']):
                st.write("<span style='color: #ff6600;'>*Please enter valid inputs for all fields (Visitors > 0, Conversions >= 0 and <= Visitors, Risk/Trust between 0-100).</span>", unsafe_allow_html=True)
            else:
                display_mde_table(st.session_state.get("num_variants", 2),
                                  st.session_state.get("baseline_visitors", 0),
                                  st.session_state.get("baseline_conversions", 0),
                                  st.session_state.get("risk", 95),
                                  st.session_state.get("trust", 80),
                                  st.session_state.get("tails", 'One-sided'))

    elif calculation_mode == "Calculate Sample Size based on MDE":
        get_user_input()
        if st.button("Calculate Sample Size", type="primary"):
            # Add Validation Block using st.session_state
            if (st.session_state.get("baseline_visitors", 0) <= 0 or
                    st.session_state.get("baseline_conversions", 0) < 0 or
                    st.session_state.get("baseline_conversions", 0) > st.session_state.get("baseline_visitors", 0) or
                    not (0 < st.session_state.get("risk", 90) <= 100) or
                    not (0 < st.session_state.get("trust", 80) <= 100) or
                    st.session_state.get("mde", 5) <= 0 or
                    st.session_state.get("tails", 'One-sided') not in ['One-sided', 'Two-sided']):
                # If input is INVALID, show an error message
                st.write("<span style='color: #ff6600;'>*Please enter valid inputs for all fields (Visitors > 0, Conversions >= 0 and <= Visitors, Risk/Trust between 0-100, MDE > 0).</span>", unsafe_allow_html=True)
            else:
                # If input IS VALID, call the calculation function
                calculate_sample_size(st.session_state.get("num_variants", 2),
                                      st.session_state.get("baseline_visitors", 0),
                                      st.session_state.get("baseline_conversions", 0),
                                      st.session_state.get("mde", 5),
                                      st.session_state.get("risk", 95),
                                      st.session_state.get("trust", 80),
                                      st.session_state.get("tails", 'One-sided'))
    else:
        st.write("### Upload Historical Data")
        st.info("Upload a CSV with columns: `date` (YYYY-MM-DD), `visitors` (count), `conversions` (count). Ideally 1-2 years of data (not more!).")
        
        uploaded_file = st.file_uploader("Upload CSV", type=['csv'])
        
        # Common inputs for the seasonal mode
        col1, col2 = st.columns(2)
        with col1:
             num_variants_s = st.number_input("Number of variants:", min_value=2, value=2, key="seas_variants")
        with col2:
             risk_s = st.number_input("Confidence level (%):", value=95, key="seas_risk")
             trust_s = st.number_input("Power (%):", value=80, key="seas_trust")
             tails_s = st.radio("Hypothesis:", ['One-sided', 'Two-sided'], key="seas_tails", horizontal=True)

        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                # Normalize columns for Prophet
                df.columns = [c.lower() for c in df.columns]
                
                # Simple column mapping attempt
                if 'date' in df.columns:
                    df = df.rename(columns={'date': 'ds'})
                
                # Check for required columns
                if not {'ds', 'visitors', 'conversions'}.issubset(df.columns):
                    st.error("CSV must contain columns: 'date' (or 'ds'), 'visitors', 'conversions'")
                else:
                    df['ds'] = pd.to_datetime(df['ds'], dayfirst=True)
                    forecast_confidence = 1 - (risk_s / 100)
                    
                    if st.button("Generate Forecast & Analysis", type="primary"):
                        with st.spinner("Running Prophet Forecast..."):
                            # Run Forecast
                            forecast_data = run_prophet_forecast(df, periods=42, interval_width=forecast_confidence)
                            
                            # Display Forecast Plot
                            st.write("### Traffic Forecast (Next 6 Weeks)")
                            
                            # Create Plotly Figure
                            fig = go.Figure()

                            # Main Line (Predicted Visitors)
                            fig.add_trace(go.Scatter(
                                x=forecast_data['ds'], 
                                y=forecast_data['pred_visitors'],
                                mode='lines',
                                name='Predicted Visitors',
                                line=dict(color='#0072B2')
                            ))

                            # Confidence Interval (Upper Bound) - Invisible line for filling
                            fig.add_trace(go.Scatter(
                                x=forecast_data['ds'], 
                                y=forecast_data['vis_upper'],
                                mode='lines',
                                line=dict(width=0),
                                showlegend=False,
                                hoverinfo='skip'
                            ))

                            # Confidence Interval (Lower Bound) - Fills up to the Upper Bound
                            fig.add_trace(go.Scatter(
                                x=forecast_data['ds'], 
                                y=forecast_data['vis_lower'],
                                mode='lines',
                                line=dict(width=0),
                                fill='tonexty', # Fills to the previous trace (vis_upper)
                                fillcolor='rgba(0, 114, 178, 0.2)', # Same blue, 0.2 opacity
                                name=f'Confidence Interval ({int(forecast_confidence * 100)}%)'
                            ))

                            fig.update_layout(
                                title="Daily Visitor Forecast",
                                yaxis_title="Visitors",
                                xaxis_title="Date",
                                hovermode="x"
                            )

                            # Render
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # Run Calculation
                            results = perform_mde_calculation_forecast(
                                forecast_data, num_variants_s, risk_s, trust_s, tails_s
                            )
                            
                            # Display Results
                            res_df = pd.DataFrame(results, columns=['Week', 'Avg Visitors / Variant', 'Relative MDE (%)'])
                            res_df['Relative MDE (%)'] = res_df['Relative MDE (%)'].map(lambda x: f"{x:.2f}%" if pd.notnull(x) else "N/A")
                            
                            st.write("### Seasonal MDE Results")
                            st.write("This table calculates MDE using the **predicted** traffic and conversion rate for each specific week, accounting for seasonality.")
                            st.table(res_df)
                            
            except Exception as e:
                st.error(f"Error parsing file: {e}")

if __name__ == "__main__":
    run()
